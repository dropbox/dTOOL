# v108 Audit: kafka.rs (2118 lines)

**Auditor:** Worker #1809
**Date:** 2025-12-25
**File:** `crates/dashflow-streaming/src/kafka.rs`
**Status:** CLEAN (0 P0 | 0 P1 | 0 P2 | 2 P3 | 2 P4)

## Summary

The kafka.rs module provides Kafka topic management utilities for DashFlow Streaming. It includes:
- Unified security configuration (`KafkaSecurityConfig`) for consistent auth across all Kafka clients
- Topic creation, deletion, listing, and existence checks
- Configurable timeouts and address family settings
- Topic provisioning helpers for main + DLQ topic pairs

The code is **production-quality** with comprehensive validation, proper error handling, retry logic with exponential backoff, and extensive test coverage.

## Audit Methodology

1. Line-by-line review of all 2118 lines
2. Analysis of security configuration handling
3. Validation of error handling and edge cases
4. Review of test coverage and integration tests

## Findings

### P0: None

No critical bugs, security vulnerabilities, or data loss risks found.

### P1: None

No correctness issues found.

### P2: None

No significant non-critical issues found.

### P3: Minor/Enhancement (2 items)

#### M-1045: delete_topic() lacks retry logic
**File:** `kafka.rs:761-813`
**Category:** Robustness/Consistency

**Observation:** `create_topic()` implements retry logic with exponential backoff (lines 658-689), but `delete_topic()` does not have equivalent retry handling. This is inconsistent and could cause spurious failures on transient network issues.

**Risk:** Low - delete operations are less common and already handle "topic doesn't exist" gracefully. The current behavior is acceptable but inconsistent.

**Recommendation (optional):** Add retry logic to `delete_topic()` for consistency with `create_topic()`.

---

#### M-1046: validate() doesn't require sasl_mechanism when protocol is SASL-based
**File:** `kafka.rs:370-413`
**Category:** Validation/Usability

**Observation:** The `validate()` function validates that `sasl_mechanism` is in the allowed list IF it's set, and validates username/password pairing. However, it doesn't require `sasl_mechanism` to be set when `security_protocol` is "sasl_ssl" or "sasl_plaintext".

```rust
// This passes validation but will fail at connect time:
KafkaSecurityConfig {
    security_protocol: "sasl_ssl".to_string(),
    sasl_mechanism: None,  // Missing!
    sasl_username: Some("user".to_string()),
    sasl_password: Some("pass".to_string()),
    ..Default::default()
}
```

**Risk:** Low - the error will surface at connection time with an rdkafka error. Users typically discover this during development.

**Recommendation (optional):** Add validation check:
```rust
if self.security_protocol.contains("sasl") && self.sasl_mechanism.is_none() {
    return Err(Error::Kafka(
        "sasl_mechanism is required when security_protocol is sasl_* based".to_string()
    ));
}
```

### P4: Informational/Cosmetic (2 items)

#### M-1047: Missing integration test for get_partition_count()
**File:** `kafka.rs:905-959`
**Category:** Test Coverage

**Observation:** The integration test suite includes tests for create/list/delete/exists operations but not `get_partition_count()`. The function uses the same code patterns so it's likely correct.

**No action needed** - the code path is well-tested indirectly.

---

#### M-1048: Env var modification in broker_address_family test
**File:** `kafka.rs:2082-2117`
**Category:** Test Hygiene

**Observation:** The test `test_get_broker_address_family_env_override()` modifies the `KAFKA_BROKER_ADDRESS_FAMILY` env var globally, which could theoretically affect parallel test runs. The test does properly save and restore the original value.

**No action needed** - tests run sequentially by default, and the restore logic is correct.

## Positive Findings

The following aspects of the code are particularly well-implemented:

1. **Unified Security Configuration (M-413):** `KafkaSecurityConfig` provides consistent security settings across all Kafka clients (producer, consumer, admin). The `from_env()` pattern with clear env var documentation is excellent.

2. **Centralized Timeouts (M-618):** `get_operation_timeout()` and `get_metadata_timeout()` with env var overrides provide operational flexibility.

3. **Configurable Address Family (M-478):** `get_broker_address_family()` auto-detects localhost vs remote and applies appropriate IPv4/IPv6 settings, with env var override capability.

4. **Comprehensive Topic Config Validation (K-1 through K-9):**
   - K-1: num_partitions >= 1 ✓
   - K-2: replication_factor >= 1 ✓
   - K-3: cleanup_policy in allowed list ✓
   - K-4: compression_type in allowed list ✓
   - K-5: delete_topic handles "topic doesn't exist" gracefully ✓
   - K-6: topic_exists uses O(1) single-topic metadata fetch ✓
   - K-7: bootstrap_servers validation (non-empty) ✓
   - K-9: min_insync_replicas validation (>= 1, <= replication_factor) ✓
   - K-10: create_topic retry logic with exponential backoff ✓

5. **Topic Provisioning (M-410):** `ensure_topic_exists()` and `ensure_topics_with_dlq()` provide idempotent topic creation with appropriate DLQ retention settings.

6. **Test Coverage:** 50+ unit tests covering configuration variants, validation edge cases, and integration tests with testcontainers.

## Conclusion

This module is **production-ready**. No fixes required. The two P3 items are minor enhancements that can be addressed opportunistically. The code demonstrates excellent defensive programming practices.
